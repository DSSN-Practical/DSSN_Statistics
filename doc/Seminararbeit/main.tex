\documentclass{article}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{url}

\title{Praktikumsarbeit DSSN WS 2014: \\ Statistik der Xodx-Simulation}
\author{Franz Teichmann}
\date{\today}


\begin{document}
\shorthandoff{"}
\maketitle

\tableofcontents
\newpage

%TODO ARBEIT statt Seminararbeit o. Praktikum

\section{Einleitung und Aufgabenstellung}

Das diesjährige DSSN-Praktikum (xodx) war in das Seminar ,,Anwendung Se-mantischer Technologien'' am Lehrstuhl für betriebliche Informationssysteme eingebettet und umfasste verschiedene praktische Aufgabenkomplexe, die von einem unabhängigen Studententeam bearbeitet wurden.\\
Die Aufgaben drehten sich darum, einen Test für die bestehende xodx-Software zu entwerfen und eine agentenbasierende Simulationssoftware als Testumgebung nach einem Komponentenmodell zu realisieren. Dabei sollte die Arbeit des Teams vom vorangegangenen Wintersemester fortgeführt werden.\\
Meine Aufgabe war es, die Statistikkomponente als zentrales Verbindungsstück zwischen der xodx-Software bzw. deren Agenten und der Simulationskontrolleinheit zu entwerfen und zu implementieren. Die Ergebnisse dieser Arbeit sollen hier übersichtlich dargestellt werden.\\
Dazu soll zunächst kurz die thematische Recherche zum Thema Anwendung Semantischer Technologien dargestellt werden, um einen Einblick in die Designentscheidungen zu geben. Danach soll die Vorarbeit aus dem letzten Jahr zusammengefasst werden, um anschließend genauer auf den entwickelten Statistikkontroller einzugehen und die Architektur zu umreißen. Anschließend sollen der Arbeitsablauf für die Simulation sowie der anschließende Auswertungsprozess erläutert werden und in der Zusammenfassung eine abschließende Darstellung der erreichten und der noch offenen Zielstellungen gegeben werden.\\
Alle Dateien sowie dieses Dokument und weitere Dokumentation sind auf Github\footnote{\url{https://github.com/DSSN-Practical/DSSN_Statistics}} zu finden.

\section{Recherche}

In diesem Kapitel sollen die Technologien vorgestellt werden, welche im praktischen Teil der Arbeit Verwendung fanden. Es handelt sich dabei um relativ umfangreiche Recherchethemen mit vielen verschiedenen Aspekten, welche unter Anderem in der Vorlesung "Semantic Web" am Lehrstuhl behandelt wurden, weshalb an dieser Stelle nur die für das Praktikum relevantesten Aspekte dargestellt werden sollen.


\subsection{Semantic Web}

- Semantic Web Vision und Internet 2.0


\subsection{Triplestores}

- Apache Jena
- Virtuoso

\subsection{Datacube-Vokabular}

- kurz wie Vortrag am Bild

\subsection{DSSN / Xodx}

- soziale Netzwerke als Schlüsselkomponente
- Schwächen und Alternativen
- distributed, social, semantic Network
- Verwendung von Zend, Saft und Erfurt Zusammenhang

%Was ist das xodx model?
\subsubsection{Zend}
%Action-Methoden in Controllerklassen

\section{Vorarbeit}

Wie bereits in Kapitel 1 beschrieben, sollte die Arbeit auf der des Studententeams aus dem vergangenen Wintersemester aufsetzen und diese fortführen. Im letzten Jahr waren es 5, später 3 Studenten, welche an der Umsetzung einer Simulation für xodx arbeiteten. Die Arbeit umfasste drei Bereiche.
\begin{enumerate}
	\item{Entwicklung einer Test-Infrastruktur\\
	Es sollten virtuelle Container erstellt werden, auf welchen die xodx-Soft-ware inklusive Virtuoso Backend läuft und welche untereinander auf getrennten Ports kommunizieren können. Zur Umsetzung dieser Aufgabe wurde Docker\footnote{Docker}gewählt. Dabei wurde geplant, dass jeweils eine Instanz von Docker auch genau eine Instanz der xodx Software, also einen Knoten im DSSN, umfasst und auf dieser Instanz nur ein Account registriert ist, welcher vom virtuellen Agenten bedient wird.}
	\item{Generierung von Testdaten\\
	Um eine möglichst realitätsgetreue Simulation zu erreichen, sollte ein Korpus aus Realdaten extrahiert und über Transformationen in eine mit Zeitstempel versehene Liste von Aktionen im sozialen Netzwerk generiert werden. Dazu wurde in Python eine App entwickelt, die über die Twitter-Api verschiedene, untereinander vernetzte Timelines extrahiert und nach XML parst.}
	\item{Planung einer Statistikkomponente\\
	Es sollte eine mögliche Umsetzung einer Statistikkomponente  recherchiert werden, um mit dieser die Software auf vorher festgelegte Fehlerklassen zu überprüfen. Als Fehlerklassen wurden Dateneffizienz, verlorene Nachrichten und Zugriffsgeschwindigkeit auf die eigene Zeitleiste festgestellt und es sollte mithilfe der Simulationssoftware ermöglicht werden, auf Unregelmäßigkeiten in diesen Gebieten zu prüfen. Die Speicherung der Daten dieser Erhebung soll ebenfalls innerhalb des Paradigma des Semantic Web erfolgen und es wurde das DataCube-Vokabular evaluiert sowie ein DataCube angelegt, der zur Speicherung der Daten verwendet werden soll. Es sollte das vom Lehrstuhl entwickelte Tool CubeViz\footnote{CubeViz} verwendet werden, um die Daten graphisch auszuwerten.}
\end{enumerate}
Mit dieser Arbeit war es möglich, dem eigentlichen Simulationsversuch näher zu kommen, auch wenn dieser aufgrund der geringen Teamgröße nicht umgesetzt werden konnte. Hier wurde im Wintersemester 2015 erneut angesetzt mit dem Ziel, alle bereits vorhandenen Komponenten zu verbinden. Dazu wurde ein Replay-Agent benötigt, welcher es ermöglicht, auf der laufenden Docker-Infrastruktur den vorhandenen Twitterkorpus ,,abzuspielen''.\\
 Zusätzlich dazu musste ein Statistikkontroller als Verbindung zwischen der Live-Instanz eines Agenten und den im DataCube hinterlegten Beobachtungen entwickelt werden. Mit letzterer Aufgabe habe ich mich beschäftigt. Dabei ist mir aufgefallen, dass der im vergangenen Jahr erstellte DataCube bewusst von der aktuellsten Empfehlung des W3C abweicht, um besser mit CubeViz zu harmonieren. Mit der Neuentwicklung von CubeViz und anderen Möglichkeiten der Auswertung (siehe Kapitel 6) ist diese Anpassung nicht mehr notwendig und der DataCube konnte auf die aktuelle Version des Vokabulars geupdatet werden.

\section{Struktur des DataCubes}

Der DataCube für die Speicherung und Auswertung der Messwerte umfasst 5 Datasets, also 5 Messgrößen. Diese sind in Tabelle 1 aufgeführt. Der Zusammenhang zwischen dieser Struktur, der Simulationsdurchführung und den notwendigen Berechnungen zur Evaluation der genannten Fehlerklassen soll in Kapitel 6 beschrieben werden.\\
\begin{table}[h]
\centering
\label{table1}
\begin{tabular}{|l|l|}
\hline
Dataset & Beschreibung \\ \hline
\texttt{xo:dataset-xoFollowers}       & Anzahl der Follower für einen Agenten            	\\ \hline
\texttt{xo:dataset-xoOUT}        & Ausgehende Nachrichten seit Start der Simulation         \\ \hline
\texttt{xo:dataset-xoIN}        & Eingegangene Nachrichten             						\\ \hline
\texttt{xo:dataset-xoTriples}        & Anzahl gespeicherter triple auf einem Knoten        	\\ \hline
\texttt{xo:dataset-xoAccess}        & Zugriffszeit auf eigene Zeitleiste             		\\ \hline
\end{tabular}
\caption{DataSets im dssn DataCube}
\end{table}\\
Jedes dieser Datasets ist durch eine Data Structure Definition näher beschrieben. Hier werden die für die Umsetzung des Datasets benötigten Dimensionen angehängt. Sie sind in Tabelle 2 auf der Folgeseite aufgelistet. Zusätzlich nennt die Data Structure Definition auch die jeweilige Messgröße, welche im dssn DataCube für jedes Dataset eindeutig gewählt wurde.
\begin{table}[t]
\centering
\label{table2}
\begin{tabular}{|l|l|}
\hline
Dimension & Beschreibung \\ \hline
\texttt{xo:refAgent}       & Identifikationsnummer des Agenten            			\\ \hline
\texttt{xo:refTime}        & Zeitpunkt der Messung, auch verwendet als Slice Key	\\ \hline
\end{tabular}
\caption{Dimensionen im dssn DataCube}
\end{table}\\
Jede Messung, also jede Observation, benötigt einen eindeutigen Bezeichner und ist genau einem Dataset zugeordnet. Sie umfasst stets zusätzlich zu den zwei Dimensionen aus Tabelle 2 den Messwert in der Dimension der Messgröße des Datasets. Es gibt im Repository dazu ein kurzes Beispiel\footnote{\url{https://github.com/DSSN-Practical/DSSN_Statistics/blob/master/observations/exampleObservations.ttl}}. In diesem sind Observations zu zwei Agenten enthalten, die sich gegenseitig folgen und zu zwei Zeitpunkten Nachrichten versenden, wobei zwischen Messzeitpunkt 1 und 2 eine Nachricht nicht korrekt übertragen wird.

\section{Architektur des Statistikkontrollers}
Der Statistikkontroller ist in PHP 5 implementiert und folgt dem von Zend verwendeten Architekturmodell MVC. Er stellt einen zusätzlichen Controller dar, der über den Bootstrapping-Prozess von xodx zur Verfügung gestellt wird und dessen Messergebnis ohne xodx-Layout direkt über die URL bzw. mit einem http-request\footnote{\url{https:github.com/DSSN-Practical/DSSN\_Statistics/blob/master/doc/example-request.php}} abfragbar ist.\\
Der Statistikkontroller ist nach dem Klassenkonzept von PHP in öffentliche (public) und klasseninterne (private) Funktionen strukturiert und arbeitet mit dem Model, an welches Sparql Queries gestellt werden, um die benötigten statistische Kennwerte zu ermitteln. Eine Zusammenfassung der ,,public'' Funktionen ist in Tabelle 3 gelistet. Diese Funktionen sind als ,,Actions'' formuliert, werden also vom Zend Bootstrapper gefunden und mit entsprechenden Einstellungen über die Schnittstelle verfügbar\footnote{verfügbare Actions: Die readStoreAction diente ausschließlich der Verhaltensanalyse der Software in Bezug auf die abgespeicherten Daten. Sie sollte in einer laufenden Produktivversion der Software nicht mehr aktiv sein, da über sie via http-request der gesamte innere Speicher des Knotens auslesbar ist.} gemacht.\\
\begin{table}[h!]
\centering
\label{table3}
\begin{tabular}{|l|l|}
\hline
\texttt{public function} & Beschreibung \\ \hline
\texttt{getStatsAction}       & Ermitteln der Kennwerte und Formatierung in turtle 	\\ \hline
\texttt{readStoreAction}      & Auslesen des Triplestores und Ausgabe zum Debugging	\\ \hline
\end{tabular}
\caption{,,public'' Funktionen des Statistikkontrollers}
\end{table}\\
Die ,,private'' Funktionen dienen zur Kapselung der einzelnen Anfragen an das Model beim Erstellen der Observations in den einzelnen Datasets. Durch diese Auslagerung von Funktionalität wird eine höhere Robustheit und des Codes erreicht und sie dient außerdem dazu, die Fehlersuche stark zu vereinfachen.

\section{Planung der Simulation, Auswertung}

In diesem Kapitel sollen die bisherige Versuchsplanung der Simulation sowie die bisher erstellten Möglichkeiten zur Auswertung des DataCube zusammengefasst werden.\\
Wie in Kapitel 3 teilweise beschrieben, ist geplant, auf einem leistungsfähigen Server zahlreiche Instanzen von Docker mit http-Schnittstellen untereinander zu initialisieren und so ein virtuelles Netzwerk aus Docker Containern aufzubauen. In diesen Containern läuft jeweils eine Instanz von xodx inklusive Virtuoso als xodx Knoten. Auf diesem Knoten ist jeweils nur ein Nutzer registriert, für den stellvertretend der virtuelle Agent in Form eines Replay-Programmes agiert.\\
Die auszuführenden Aktionen sind an Realdaten, genauer an einem Twitter Export im xml Format, orientiert. Diese sind mit normierten Zeitstempeln und Identifikatoren für Agenten versehenen, werden jeder Instanz zur Verfügung gestellt und von der Replay Struktur des Agenten in Form von http-requests ausgeführt. Es gibt eine einheitliche Systemzeit auf dem Server, welche das Fortschreiten der Simulation sichert.\\
Zu regelmäßigen Zeitpunkten wird diese Simulationszeit angehalten und es wird eine Statistik erstellt. Dies ist notwendig, um während der Messung selbige nicht durch Aktionen der Agenten zu verfälschen. Zur Durchführung der Messung ist ein spezieller Agent nötig, der eine Liste der Verbindungen zu jedem aktiven Agenten besitzt und von diesen rekursiv die Antworten des Statistikkontrollers (Observations) sammelt und speichert.\\
Dieser besondere Agent besitzt auch den Datensatz des DataCube, dem in der Auswertungsphase die Observations hinzugefügt werden. Die Auswertung soll in vier Schritten geschehen:
\begin{enumerate}
	\item{Transformation\\
	Sowohl der DataCube als auch die Observations sind in zur Erhöhung der Lesbarkeit in turtle serialisiert. Für Schritt 2 ist es jedoch notwendig, dass die Dateien in RDF/XML vorliegen. Diese Umwandlung ist relativ einfach mit einem Kommandozeilen Tool namens ,,Rapper''\footnote{Rapper:} durchführbar. Ein Beispielbefehl dafür ist in Abbildung 1 zu sehen.\\
	\begin{figure}[h]
	\centering
	\texttt{\$ rapper -i turtle -o rdfxml observations/exampleObservations.ttl  > observations/exampleObservations.rdf}
	\caption{Beispielbefehl Rapper}
	\end{figure}
	}\\
	Diese Transformation hat zudem den Vorteil, dass eventuelle Fehler im RDF Graphen wie zum Beispiel falsch zusammengefügte Zeilen oder fehlende Präfixe frühzeitig erkannt und bereits in diesem Schritt behoben werden können.\\
	\item{Überprüfung auf Validität bzw. Evaluation\\
	Der nächste Schritt ist die Validitätsprüfung des DataCube. Dafür liegt ein ausführbares Java Archiv\footnote{\url{https://github.com/DSSN-Practical/DSSN_Statistics/blob/master/SparqlTester/bin/CubeValidator.jar}} im Repository, welches unter Verwendung des Apache Jena Frameworks das DataCube File sowie die Observations in den Arbeitsspeicher liest und darauf die Sparql queries ausführen kann, welche vom W3C zur Validierung eines DataCube zur Verfügung gestellt wurden. Diese liegen im Verzeichnis \texttt{/evaluation}. Das Archiv ist für die Verwendung auf der Kommandozeile auslegt und nimmt dementsprechend Parameter entgegen. Leider ist es mit Apache Jena nur möglich, RDF/XML serialisierte Dateien einzulesen (siehe Schritt 1). Ein Beispielbefehl ist in Bild 2 zu sehen.\\
	\begin{figure}[h]
	\centering
	\texttt{\$ java -jar SparqlTester/bin/CubeValidator.jar datacubes/dssn\_cubeXML.rdf observations/exampleObservations.rdf evaluation/}
	\caption{Beispielbefehl DataCube Validierung/Evaluation}
	\end{figure}\\
	Die Ausgabe ist eine Liste aller bestandener oder nicht bestandener Tests. Sollte ein Test nicht bestanden werden, ist auch ein kurzer Kommentar und die fehlgeschlagene query zu sehen. Sollten zum Beispiel im Verlauf der Simulation der unwahrscheinliche Fall eintreten, dass zwei Observations den gleichen Bezeichner vom Zufallsgenerator zugewiesen bekommen, würde ein solcher Fehler an dieser Stelle herausgefiltert und könnte behoben werden.
	}
	\item{Überprüfung auf verlorene Nachrichten\\
	Dies ist die erste zur Prüfende Klasse von Fehlern, welche während der Simulation auftreten können. Da in xodx die Versendung von Nachrichten auf Basis eines Abonnement eines anderen Nutzers geschieht und dieses Abonnement dezentral gespeichert wird, ist es für einen Nutzer von seinem eigenen Knoten aus nicht nachvollziehbar, an wie viele Rezipienten die Nachricht in seiner Zeitleiste versendet wurde. Diese Information lässt sich nur aus der Gesamtheit der Daten in der Statistik schließen. Hierfür wurde ebenfalls ein ausführbares Java Archiv geschrieben. Mit diesem ist es möglich, beliebige Sparql queries auf der Wissensbasis bestehend aus DataCube und Observations auszuführen. Einige für die Auswertung prädestinierte queries befinden sich im Unterordner \texttt{/queries}. In Abbildung 3 ist der Befehl für die Auswertung auf verlorene Nachrichten zu sehen.
	\begin{figure}[h]
	\centering
	\texttt{\$ java -jar SparqlTester/bin/SelectTester.jar datacubes/dssn\_cubeXML.rdf observations/exampleObservations.rdf queries/checkLostMessages.sparql}
	\caption{Beispielbefehl Test auf verlorene Nachrichten}
	\end{figure}\\
	Dabei ist zu beachten, dass bei einem neuen Abonnement in xodx die gesamte Zeitleiste des Users ,,nachgezogen'' wird, weshalb alle versandten und empfangenen Nachrichten immer von Beginn der Simulation gezählt werden.
	}
	\item{Visualisierung: Dateneffizienz und Zugriffszeit\\
	Diese beiden Fehlerklassen eigenen sich besonders dafür, in einer Grafik wie zum Beispiel einem Graphenplot ausgewertet zu werden. Dafür kann der DataCube inklusive Observations zum Beispiel in CubeViz eingelesen werden und mit diesem Tool automatisch eine Visualisierung der Zeitverläufe der gespeicherten Triples und der eventuell ansteigenden Zugriffszeit erstellt werden. Leider war zum Zeitpunkt des Praktikums kein Release des neu entwickelten CubeViz verfügbar, um diesen Prozess zu testen.	
	}
\end{enumerate}

\section{Zusammenfassung}

- "Mitglied abgesprungen, kein Test möglich"

\bibliographystyle{plain}
\bibliography{references.bib}
\end{document}
