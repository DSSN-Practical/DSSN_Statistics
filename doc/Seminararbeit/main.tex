\documentclass{article}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{url}

\title{Praktikumsarbeit DSSN WS 2014: \\ Statistik der Xodx-Simulation}
\author{Franz Teichmann}
\date{\today}


\begin{document}
\shorthandoff{"}
\maketitle

\tableofcontents
\newpage

%TODO ARBEIT statt Seminararbeit o. Praktikum

\section{Einleitung und Aufgabenstellung}

Das diesjährige DSSN-Praktikum (xodx) war in das Seminar ,,Anwendung Se-mantischer Technologien'' am Lehrstuhl für betriebliche Informationssysteme eingebettet und umfasste verschiedene praktische Aufgabenkomplexe, die von einem unabhängigen Studententeam bearbeitet wurden.\\
Die Aufgaben drehten sich darum, einen Test für die bestehende xodx-Software zu entwerfen und eine agentenbasierende Simulationssoftware als Testumgebung nach einem Komponentenmodell zu realisieren. Dabei sollte die Arbeit des Teams vom vorangegangenen Wintersemester fortgeführt werden.\\
Meine Aufgabe war es, die Statistikkomponente als zentrales Verbindungsstück zwischen der xodx-Software bzw. deren Agenten und der Simulationskontrolleinheit zu entwerfen und zu implementieren. Die Ergebnisse dieser Arbeit sollen hier übersichtlich dargestellt werden.\\
Dazu soll zunächst kurz die thematische Recherche zum Thema Anwendung Semantischer Technologien dargestellt werden, um einen Einblick in die Designentscheidungen zu geben. Danach soll die Vorarbeit aus dem letzten Jahr zusammengefasst werden, um anschließend genauer auf den entwickelten Statistikkontroller einzugehen und die Architektur zu umreißen. Anschließend sollen der Arbeitsablauf für die Simulation sowie der anschließende Auswertungsprozess erläutert werden und in der Zusammenfassung eine abschließende Darstellung der erreichten und der noch offenen Zielstellungen gegeben werden.\\
Alle Dateien sowie dieses Dokument und weitere Dokumentation sind auf Github\footnote{\url{https://github.com/DSSN-Practical/DSSN_Statistics}} zu finden.

\section{Recherche}

In diesem Kapitel sollen die Technologien vorgestellt werden, welche im praktischen Teil der Arbeit Verwendung fanden. Es handelt sich dabei um relativ umfangreiche Recherchethemen mit vielen verschiedenen Aspekten, welche unter Anderem in der Vorlesung "Semantic Web" am Lehrstuhl behandelt wurden, weshalb an dieser Stelle nur die für das Praktikum relevantesten Aspekte dargestellt werden sollen.


\subsection{Semantic Web}

- Semantic Web Vision und Internet 2.0


\subsection{Triplestores}

- Apache Jena
- Virtuoso

\subsection{Datacube-Vokabular}

- kurz wie Vortrag am Bild

\subsection{DSSN / Xodx}

- soziale Netzwerke als Schlüsselkomponente
- Schwächen und Alternativen
- distributed, social, semantic Network
- Verwendung von Zend, Saft und Erfurt Zusammenhang
%Was ist das xodx model?

\section{Vorarbeit}

Wie bereits in Kapitel 1 beschrieben, sollte die Arbeit auf der des Studententeams aus dem vergangenen Wintersemester aufsetzen und diese fortführen. Im letzten Jahr waren es 5, später 3 Studenten, welche an der Umsetzung einer Simulation für xodx arbeiteten. Die Arbeit umfasste drei Bereiche.
\begin{enumerate}
	\item{Entwicklung einer Test-Infrastruktur\\
	Es sollten virtuelle Container erstellt werden, auf welchen die xodx-Soft-ware inklusive Virtuoso Backend läuft und welche untereinander auf getrennten Ports kommunizieren können. Zur Umsetzung dieser Aufgabe wurde Docker\footnote{Docker}gewählt. Dabei wurde geplant, dass jeweils eine Instanz von Docker auch genau eine Instanz der xodx Software, also einen Knoten im DSSN, umfasst und auf dieser Instanz nur ein Account registriert ist, welcher vom virtuellen Agenten bedient wird.}
	\item{Generierung von Testdaten\\
	Um eine möglichst realitätsgetreue Simulation zu erreichen, sollte ein Korpus aus Realdaten extrahiert und über Transformationen in eine mit Zeitstempel versehene Liste von Aktionen im sozialen Netzwerk generiert werden. Dazu wurde in Python eine App entwickelt, die über die Twitter-Api verschiedene, untereinander vernetzte Timelines extrahiert und nach XML parst.}
	\item{Planung einer Statistikkomponente\\
	Es sollte eine mögliche Umsetzung einer Statistikkomponente  recherchiert werden, um mit dieser die Software auf vorher festgelegte Fehlerklassen zu überprüfen. Als Fehlerklassen wurden Dateneffizienz, verlorene Nachrichten und Zugriffsgeschwindigkeit auf die eigene Zeitleiste festgestellt und es sollte mithilfe der Simulationssoftware ermöglicht werden, auf Unregelmäßigkeiten in diesen Gebieten zu prüfen. Die Speicherung der Daten dieser Erhebung soll ebenfalls innerhalb des Paradigma des Semantic Web erfolgen und es wurde das DataCube-Vokabular evaluiert sowie ein DataCube angelegt, der zur Speicherung der Daten verwendet werden soll. Es sollte das vom Lehrstuhl entwickelte Tool CubeViz\footnote{CubeViz} verwendet werden, um die Daten graphisch auszuwerten.}
\end{enumerate}
Mit dieser Arbeit war es möglich, dem eigentlichen Simulationsversuch näher zu kommen, auch wenn dieser aufgrund der geringen Teamgröße nicht umgesetzt werden konnte. Hier wurde im Wintersemester 2015 erneut angesetzt mit dem Ziel, alle bereits vorhandenen Komponenten zu verbinden. Dazu wurde ein Replay-Agent benötigt, welcher es ermöglicht, auf der laufenden Docker-Infrastruktur den vorhandenen Twitterkorpus ,,abzuspielen''.\\
 Zusätzlich dazu musste ein Statistikkontroller als Verbindung zwischen der Live-Instanz eines Agenten und den im DataCube hinterlegten Beobachtungen entwickelt werden. Mit letzterer Aufgabe habe ich mich beschäftigt. Dabei ist mir aufgefallen, dass der im vergangenen Jahr erstellte DataCube bewusst von der aktuellsten Empfehlung des W3C abweicht, um besser mit CubeViz zu harmonieren. Mit der Neuentwicklung von CubeViz und anderen Möglichkeiten der Auswertung (siehe Kapitel 6) ist diese Anpassung nicht mehr notwendig und der DataCube konnte auf die aktuelle Version des Vokabulars geupdatet werden.

\section{Struktur des DataCubes}

Der DataCube für die Speicherung und Auswertung der Messwerte umfasst 5 Datasets, also 5 Messgrößen. Diese sind in Tabelle 1 aufgeführt. Der Zusammenhang zwischen dieser Struktur, der Simulationsdurchführung und den notwendigen Berechnungen zur Evaluation der genannten Fehlerklassen soll in Kapitel 6 beschrieben werden.\\
\begin{table}[h]
\centering
\label{table1}
\begin{tabular}{|l|l|}
\hline
Dataset & Beschreibung \\ \hline
\texttt{xo:dataset-xoFollowers}       & Anzahl der Follower für einen Agenten            	\\ \hline
\texttt{xo:dataset-xoOUT}        & Ausgehende Nachrichten seit Start der Simulation         \\ \hline
\texttt{xo:dataset-xoIN}        & Eingegangene Nachrichten             						\\ \hline
\texttt{xo:dataset-xoTriples}        & Anzahl gespeicherter triple auf einem Knoten        	\\ \hline
\texttt{xo:dataset-xoAccess}        & Zugriffszeit auf eigene Zeitleiste             		\\ \hline
\end{tabular}
\caption{DataSets im dssn DataCube}
\end{table}\\
Jedes dieser Datasets ist durch eine Data Structure Definition näher beschrieben. Hier werden die für die Umsetzung des Datasets benötigten Dimensionen angehängt. Sie sind in Tabelle 2 auf der Folgeseite aufgelistet. Zusätzlich nennt die Data Structure Definition auch die jeweilige Messgröße, welche im dssn DataCube für jedes Dataset eindeutig gewählt wurde.
\begin{table}[t]
\centering
\label{table2}
\begin{tabular}{|l|l|}
\hline
Dimension & Beschreibung \\ \hline
\texttt{xo:refAgent}       & Identifikationsnummer des Agenten            			\\ \hline
\texttt{xo:refTime}        & Zeitpunkt der Messung, auch verwendet als Slice Key	\\ \hline
\end{tabular}
\caption{Dimensionen im dssn DataCube}
\end{table}\\
Jede Messung, also jede Observation, benötigt einen eindeutigen Bezeichner und ist genau einem Dataset zugeordnet. Sie umfasst stets zusätzlich zu den zwei Dimensionen aus Tabelle 2 den Messwert in der Dimension der Messgröße des Datasets. Es gibt im Repository dazu ein kurzes Beispiel\footnote{\url{https://github.com/DSSN-Practical/DSSN_Statistics/blob/master/observations/exampleObservations.ttl}}. In diesem sind Observations zu zwei Agenten enthalten, die sich gegenseitig folgen und zu zwei Zeitpunkten Nachrichten versenden, welche fehlerfrei den jeweils anderen Agenten erreichen.

\section{Architektur des Statistikkontrollers}
Der Statistikkontroller ist in php5 implementiert und folgt dem von Zend verwendeten Architekturmodell MVC. Er stellt einen zusätzlichen Controller dar, der über den bootstrapping-Prozess von xodx zur Verfügung gestellt wird und dessen Messergebnis ohne xodx-Layout direkt über die URL bzw. mit einem http-request\footnote{\url{https:github.com/DSSN-Practical/DSSN\_Statistics/blob/master/doc/example-request.php}} abfragbar ist.\\
Er untergliedert sich in 


- public
- private
- Verwendung xodx Model
- Aufruf bei jedem Messzeitpunkt bei jedem Agenten geplant

\section{Planung der Auswertung}

- am Datenflussdiagramm?
- zur Auswertung gehört 
1. Überprüfung des Datacube auf Validität
	%Prüfung auf Kollisionen in den Bezeichnern. Zufällig generiert, daher nicht prinzipiell auszuschließen
2. Auswertung nach Gesichtspunkten
2.1. Verlorene Nachrichten

3. Visualisierung
3.1. Möglichkeiten mit CubeViz

\section{Zusammenfassung}

- "Mitglied abgesprungen, kein Test möglich"

\bibliographystyle{plain}
\bibliography{references.bib}
\end{document}
